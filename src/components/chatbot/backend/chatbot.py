import gc
import numbers
import os
import pickle
import re
import sys
import threading
import time
import traceback
from collections import defaultdict
from datetime import datetime
from pathlib import Path

import faiss
import numpy as np
import pytz
import requests
from dotenv import load_dotenv
from flask import Flask, jsonify, request
from flask_cors import CORS
from langchain.chains import RetrievalQA
from langchain.embeddings.base import Embeddings
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from supabase import Client, create_client

print("Starting chatbot initialization...")

# Load environment variables from .env file
load_dotenv()

# Force garbage collection at startup
import gc
gc.collect()

# Handle encoding for Windows
if sys.platform.startswith("win"):
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())


def safe_print(text):
    """Safely print text that may contain Unicode characters"""
    try:
        print(text)
    except UnicodeEncodeError:
        safe_text = text.encode("ascii", "replace").decode("ascii")
        print(safe_text)


print("Loading environment variables...")
env_path = Path(__file__).resolve().parents[4] / ".env.local"
load_dotenv(dotenv_path=env_path)
print("Environment variables loaded")

# Initialize Flask app
print("Initializing Flask app...")
app = Flask(__name__)

# Get allowed origins from environment variable or use default in development
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "http://localhost:3000,http://localhost:5173,http://localhost:5800,http://localhost:8080,https://kushagra-singh.vercel.app/,https://kushagra-singh.vercel.app")
allowed_origins = [origin.strip() for origin in ALLOWED_ORIGINS.split(",")]

# Enable CORS with specific origins
CORS(
    app,
    origins=allowed_origins,
    supports_credentials=True,
    allow_headers="*",
    methods=["GET", "POST", "OPTIONS"],
)
print("Flask app initialized with CORS")

# Rate limiting
class RateLimiter:
    def __init__(self, max_requests=60, window_seconds=60):
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests = defaultdict(list)

    def is_allowed(self, client_ip):
        now = time.time()
        # Clean old requests
        self.requests[client_ip] = [
            req_time
            for req_time in self.requests[client_ip]
            if now - req_time < self.window_seconds
        ]

        # Check if under limit
        if len(self.requests[client_ip]) < self.max_requests:
            self.requests[client_ip].append(now)
            return True
        return False

rate_limiter = RateLimiter(max_requests=30, window_seconds=60)  # 30 requests per minute


def clean_malformed_html(text):
    """
    Clean up malformed HTML links that might be generated by the LLM
    """
    # Remove malformed HTML link patterns
    # Pattern: text with HTML attributes but broken structure
    malformed_pattern = re.compile(
        r'([^>]*)" target="_blank" rel="noopener noreferrer" style="[^"]*">([^<]*)>([^<]*)'
    )
    text = malformed_pattern.sub(r"\1", text)

    # Remove any remaining broken HTML tags
    broken_html_pattern = re.compile(r"<[^>]*>[^<]*>[^<]*")
    text = broken_html_pattern.sub("", text)

    return text


def make_links_clickable(text):
    """
    Convert plain text URLs to HTML anchor tags while properly handling trailing punctuation.
    Also handles URLs in backticks.
    """
    # First, clean up any malformed HTML
    text = clean_malformed_html(text)

    # First, let's check if the text already contains HTML links
    if "<a href=" in text:
        # If HTML links already exist, don't process further
        return text
        
    # Handle URLs in backticks: `http://example.com`
    backtick_pattern = re.compile(r'`(https?://[^`]+)`')
    text = backtick_pattern.sub(r'<a href="\1" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 hover:underline font-medium border-b border-blue-300 pb-0.5 transition-colors">\1</a>', text)

    # Pattern to match URLs that are not already in HTML tags
    url_pattern = re.compile(r'(?<!["\'>])(https?://[^\s<>"]+?)(?=[.,!?:;\)]?(?:\s|$))')

    def replace_match(match):
        url = match.group(1)
        # Remove trailing punctuation that might be part of the URL
        if url.endswith(")") and url.count("(") < url.count(")"):
            url = url[:-1]
        elif url.endswith(".") and not url.endswith(".."):
            url = url[:-1]
        elif url.endswith(","):
            url = url[:-1]

        return f'<a href="{url}" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 hover:underline font-medium border-b border-blue-300 pb-0.5 transition-colors">{url}</a>'

    text = url_pattern.sub(replace_match, text)
    
    # Format numbered lists for better styling
    numbered_list_pattern = re.compile(r'^(\d+)\.\s+(.+)$', re.MULTILINE)
    text = numbered_list_pattern.sub(r'<div class="flex items-start mb-3"><span class="font-bold mr-2 text-purple-600 min-w-[20px] text-right">\1.</span><span class="flex-1">\2</span></div>', text)
    
    # Format bullet points for better styling
    bullet_list_pattern = re.compile(r'^[-•]\s+(.+)$', re.MULTILINE)
    text = bullet_list_pattern.sub(r'<div class="flex items-start mb-3 ml-2"><span class="mr-2 text-purple-600">•</span><span class="flex-1">\1</span></div>', text)
    
    return text

# Load embeddings and FAISS index
print("Setting up file paths...")
script_dir = os.path.dirname(os.path.abspath(__file__))
print(f"Script directory: {script_dir}")

print("Loading embeddings.pkl file...")
with open(os.path.join(script_dir, "embeddings.pkl"), "rb") as f:
    data = pickle.load(f)
texts = data["data"]  # Updated to match the new embeddings.pkl structure
embeddings_array = data["embeddings"]
print(f"Loaded {len(texts)} text entries from embeddings.pkl")

print("Loading FAISS index...")
index = faiss.read_index(os.path.join(script_dir, "faiss.index"))
print("FAISS index loaded successfully")

# Load API configurations
print("Loading API configurations...")
HF_API_URL = os.getenv("HF_API_URL")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not HF_API_URL or not HF_API_TOKEN:
    print("Warning: HF_API_URL or HF_API_TOKEN not set. Embedding functionality will be limited.")

if not GROQ_API_KEY:
    print("Warning: GROQ_API_KEY not set. LLM functionality will be limited.")
else:
    print("Initializing Groq LLM...")
    llm = ChatGroq(
        model_name="llama-3.3-70b-versatile",
        temperature=0.5,
        groq_api_key=GROQ_API_KEY,
        max_tokens=1024,
    )
    print("Groq LLM initialized")

# Initialize Supabase client if credentials are available
supabase_client = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("Supabase client initialized successfully")
    except Exception as e:
        print(f"Error initializing Supabase client: {e}")
else:
    print("Warning: SUPABASE_URL or SUPABASE_KEY not set. Logging functionality will be limited.")

# Query embedding cache
query_embedding_cache = {}

def embed_query(query):
    """Get embeddings for a query using HuggingFace API"""
    if query in query_embedding_cache:
        return query_embedding_cache[query]

    # Add retry logic for API calls
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.post(
                HF_API_URL,
                headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
                json={"inputs": query},
                timeout=30,
            )
            
            if response.status_code == 200:
                embedding = response.json()
                query_embedding_cache[query] = embedding
                return embedding
            
            if response.status_code == 429 and attempt < max_retries - 1:  # Rate limited
                wait_time = (2**attempt) * 2  # Exponential backoff
                print(f"Rate limited, waiting {wait_time} seconds before retry {attempt + 1}")
                time.sleep(wait_time)
                continue
                
            # If we get here, there was an error
            print(f"Error from HuggingFace API: {response.status_code} - {response.text}")
            return None
            
        except Exception as e:
            print(f"Exception during embedding API call: {e}")
            if attempt < max_retries - 1:
                wait_time = (2**attempt) * 2
                print(f"Retrying in {wait_time} seconds... (attempt {attempt + 1})")
                time.sleep(wait_time)
            else:
                print("Max retries reached. Returning None.")
                return None
    
    return None

def search_similar_texts(query_embedding, top_k=5):
    """Search for similar texts using FAISS index"""
    if query_embedding is None:
        return []
    
    try:
        # Convert to numpy array and ensure correct shape
        query_embedding_np = np.array(query_embedding).astype('float32').reshape(1, -1)
        
        # Search the FAISS index
        distances, indices = index.search(query_embedding_np, top_k)
        
        # Get the corresponding texts
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(texts):
                results.append({
                    "text": texts[idx],
                    "score": float(distances[0][i])
                })
        
        return results
    except Exception as e:
        print(f"Error during FAISS search: {e}")
        return []

def log_conversation(user_id, user_message, bot_response):
    """Log conversation to Supabase if available"""
    if not supabase_client:
        print("Supabase client not initialized, skipping logging")
        return
    
    try:
        # For anonymous users (no user_id), set user_id to NULL
        log_data = {
            "user_message": user_message,
            "bot_response": bot_response
        }
        
        # Only add user_id if it's provided and not None
        if user_id:
            log_data["user_id"] = user_id
            
        # Execute the insert with detailed error handling
        result = supabase_client.table("chatbot_logs").insert(log_data).execute()
        print(f"Conversation logged to Supabase: {result}")
    except Exception as e:
        print(f"Error logging to Supabase: {e}")
        print(f"Error details: {str(e)}")
        # Print the traceback for debugging
        import traceback
        traceback.print_exc()

def generate_response(query, similar_texts, user_id=None):
    """Generate a response using Groq LLM"""
    if not GROQ_API_KEY:
        return "I'm sorry, but the LLM service is currently unavailable. Please try again later."
    
    try:
        # Create context from similar texts
        context = "\n\n".join([item["text"] for item in similar_texts])
        
        # Print debug information
        print(f"Generating response for query: {query}")
        print(f"Context length: {len(context)} characters")
        print(f"Number of similar texts: {len(similar_texts)}")
        
        # Use the initialized LLM client
        system_message = "You are an AI assistant for Kushagra's portfolio website. Use the following context to answer questions. If you don't know the answer, just say that you don't know."
        user_message = f"Context:\n{context}\n\nQuestion: {query}"
        
        print("Sending request to Groq API...")
        response = llm.invoke([
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ])
        
        print("Successfully received response from Groq API")
        response_text = response.content
        
        # Format the response
        formatted_response = make_links_clickable(response_text)
        
        # Log the conversation
        if user_id:
            log_conversation(user_id, query, formatted_response)
        
        return formatted_response
    
    except Exception as e:
        print(f"Error generating response: {e}")
        traceback.print_exc()  # Print full traceback for debugging
        return "I'm sorry, but I encountered an error while processing your request. Please try again later."

# API endpoints
@app.route("/api/chat", methods=["POST"])
def chat():
    """Handle chat requests"""
    # Get client IP for rate limiting
    client_ip = request.remote_addr
    
    # Check rate limit
    if not rate_limiter.is_allowed(client_ip):
        return jsonify({
            "error": "Rate limit exceeded. Please try again later."
        }), 429
    
    # Get request data
    data = request.json
    query = data.get("message", "")
    user_id = data.get("user_id", None)
    
    if not query:
        return jsonify({
            "error": "No message provided"
        }), 400
    
    try:
        # Get query embedding
        query_embedding = embed_query(query)
        
        # Search for similar texts
        similar_texts = search_similar_texts(query_embedding)
        
        # Generate response
        response = generate_response(query, similar_texts, user_id)
        
        # Log to Supabase
        try:
            supabase_url = os.getenv("SUPABASE_URL")
            supabase_key = os.getenv("SUPABASE_KEY")
            
            if supabase_url and supabase_key:
                supabase: Client = create_client(supabase_url, supabase_key)
                
                log_data = {
                    "user_id": user_id,
                    "user_message": query,
                    "bot_response": response,
                    "timestamp": datetime.now(pytz.UTC).isoformat()
                }
                
                result = supabase.table("chatbot_logs").insert(log_data).execute()
                print(f"Logged chat interaction: {result}")
            else:
                print("Supabase credentials not found, skipping logging")
                
        except Exception as log_error:
            print(f"Error logging to Supabase: {log_error}")
            # Don't fail the request if logging fails
        
        # Return the response
        return jsonify({
            "response": response
        })
    except Exception as e:
        print(f"Error in chat endpoint: {str(e)}")
        return jsonify({
            "response": "I'm sorry, but I encountered an error while processing your request. Please try again later."
        })

@app.route("/api/health", methods=["GET"])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "ok",
        "timestamp": time.time()
    })

# Run the app
if __name__ == "__main__":
    # Get port from environment variable (Render sets PORT, local dev can use CHATBOT_PORT)
    port = int(os.getenv("PORT", os.getenv("CHATBOT_PORT", 5800)))
    debug_mode = os.getenv("FLASK_ENV", "production") == "development"
    
    # Print environment info
    env_type = "Development" if debug_mode else "Production"
    print(f"Running in {env_type} mode on port {port}")
    print(f"Allowed origins: {allowed_origins}")
    
    app.run(host="0.0.0.0", port=port, debug=debug_mode)
    print(f"Flask app running on port {port}")
